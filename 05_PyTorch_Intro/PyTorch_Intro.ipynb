{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to deep learning using PyTorch\n",
    "\n",
    "In this tutorial, we go over the basics of building deep learning models in python. We will make use of the following python packages.\n",
    "\n",
    " 1. pytorch and torchvision. See [pytorch.org](http://pytorch.org) for installation. If you're installing on a computer with a compatible GPU, make sure to install the GPU version of pytorch (i.e., select a CUDA version).\n",
    "\n",
    " 2. matplotlib. See [matplotlib.org](http://matplotlib.org) for installation.\n",
    " \n",
    " 3. numpy. See [numpy.org](http://numpy.org) for installation.\n",
    " \n",
    " Acknowledgement: This tutorial was created by Alaa ElKhatib - previous TA for ECE457B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensors\n",
    "\n",
    " Tensors are multidimensional arrays. PyTorch uses tensors to store model parameters, gradients, data, etc.\n",
    "\n",
    " PyTorch provides many functions to create tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2],\n",
      "        [3, 4]])\n"
     ]
    }
   ],
   "source": [
    "print(torch.tensor([[1, 2], [3, 4]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "print(torch.ones(3, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.6434, 0.4795, 0.4872, 0.1332],\n",
      "        [0.8152, 0.3405, 0.5804, 0.3657],\n",
      "        [0.2588, 0.7215, 0.1119, 0.9151]])\n"
     ]
    }
   ],
   "source": [
    "print(torch.rand(3, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " PyTorch also provides functions to interface with numpy objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x = [3 2 2 7], y = tensor([3, 2, 2, 7], dtype=torch.int32), z = [3 2 2 7]\n"
     ]
    }
   ],
   "source": [
    "x = np.random.randint(0, 10, 4)\n",
    "y = torch.from_numpy(x)\n",
    "z = y.numpy()\n",
    "\n",
    "print(f'x = {x}, y = {y}, z = {z}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensor attributes and methods\n",
    "\n",
    " Tensor have many attributes and methods. Some noteworthy ones are illustarted below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 2., 3., 4.]) torch.float32\n",
      "tensor([1, 2, 3, 4]) torch.int64\n",
      "tensor([[0.5793, 0.0591, 0.2013, 0.1477],\n",
      "        [0.8553, 0.9286, 0.6493, 0.8766],\n",
      "        [0.4449, 0.0184, 0.1605, 0.5377]]) cpu\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([1, 2, 3, 4], dtype=torch.float)\n",
    "print(x, x.dtype)\n",
    "x = x.to(torch.int64)  # type conversion\n",
    "print(x, x.dtype)\n",
    "\n",
    "x = torch.rand(3, 4, device=torch.device('cpu'))\n",
    "print(x, x.device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " the .to() also moves tensors from cpu to gpu and back\n",
    " attempting to move tensor to gpu throws an error\n",
    " when it's not available, so it's common practice\n",
    " to check first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0041, 0.2936, 0.0258, 0.7921],\n",
      "        [0.8515, 0.8661, 0.0691, 0.1757],\n",
      "        [0.7579, 0.3465, 0.7950, 0.1114]], device='cuda:0') cuda:0\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():  # checks gpu availablity\n",
    "    x = x.to(torch.device('cuda'))\n",
    "    print(x, x.device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " .to() can also be used to change one tensor to\n",
    " have the same dtype and device as another"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 2., 3.]) torch.float32 cpu\n",
      "tensor([1, 2, 3], device='cuda:0') torch.int64 cuda:0\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([1, 2, 3], dtype=torch.float)\n",
    "y = torch.tensor([4], dtype=torch.int64)\n",
    "if torch.cuda.is_available():\n",
    "    y = y.to(torch.device('cuda'))\n",
    "\n",
    "z = x.to(y)\n",
    "print(x, x.dtype, x.device)\n",
    "print(z, z.dtype, z.device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining a neural network model\n",
    "\n",
    " The simplest (and hence least flexible) way to define a network is using the Sequential class. \n",
    "\n",
    " As you might expect from the name, this allows us to define networks as sequences of layers, with the output of each layer fed as input to the next. \n",
    " \n",
    " The argument to Sequential is an *OrderedDict* object, where each key-value pair represents a layer and a name to identify it. \n",
    " \n",
    " So, in the example below, we can subsequently reference the first layer by net.hidden_1. We can also access the first layer's parameters by net.hidden_1.weight and net.hidden_1.bias. Finally, we can iterate over all model parameters by using the net.parameters() method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (hidden_1): Linear(in_features=10, out_features=10, bias=True)\n",
      "  (act_1): ReLU()\n",
      "  (hidden_2): Linear(in_features=10, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "net = torch.nn.Sequential(OrderedDict([\n",
    "    ('hidden_1', torch.nn.Linear(10, 10)),\n",
    "    ('act_1', torch.nn.ReLU()),\n",
    "    ('hidden_2', torch.nn.Linear(10, 1))\n",
    "]))\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can subsequently make predictions with net by calling it on a tensor (of the shape it expects). For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.3133]], grad_fn=<AddmmBackward>)\n"
     ]
    }
   ],
   "source": [
    "print(net(torch.rand(1, 10)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " PyTorch provides a more flexible way to define nets by subclassing from the torch.nn.Module class. For instance, this allows us to define a forward pass that does go through the layers sequentially. In the example below, the net has 2 branches (or columns) that merge before the final layer.\n",
    " \n",
    "In most cases, one would only need to define the forward pass."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MyNet(\n",
      "  (hidden_1a): Linear(in_features=10, out_features=5, bias=True)\n",
      "  (hidden_1b): Linear(in_features=10, out_features=5, bias=True)\n",
      "  (hidden_2): Linear(in_features=10, out_features=1, bias=True)\n",
      ")\n",
      "tensor([[0.4293]], grad_fn=<AddmmBackward>)\n"
     ]
    }
   ],
   "source": [
    "class MyNet(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyNet, self).__init__()\n",
    "        self.hidden_1a = torch.nn.Linear(10, 5)\n",
    "        self.hidden_1b = torch.nn.Linear(10, 5)\n",
    "        self.hidden_2 = torch.nn.Linear(10, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        z1 = self.hidden_1a(x)\n",
    "        z2 = self.hidden_1b(x)\n",
    "        z = torch.cat([z1, z2], dim=1)\n",
    "        f1_z = torch.nn.functional.relu(z)\n",
    "        out = self.hidden_2(f1_z)\n",
    "        return out\n",
    "\n",
    "\n",
    "net = MyNet()\n",
    "print(net)\n",
    "print(net(torch.rand(1, 10)))  # try forward pass on random sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iterating over data\n",
    "\n",
    " Training neural nets involves iterating over datasets, often in batches. PyTorch provides the DataLoader class to facilitate this. A DataLoader wraps around a Dataset and provides an iterator for it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 8]) torch.Size([16])\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "data = torch.rand(100, 8)  # 100 8-dimensional samples\n",
    "labels = torch.randint(0, 2, (100,), dtype=torch.int64)\n",
    "dataset = TensorDataset(data, labels)\n",
    "loader = DataLoader(dataset, batch_size=16, shuffle=True)\n",
    "for x, y in loader:\n",
    "    print(x.shape, y.shape)  # get first batch and break\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Of course, we can always iterate over tensors directly, but using the provided DataLoader should be faster. Also, the DataLoader class provides options for shuffling, batching, and various sampling strategies.\n",
    "\n",
    "## Torchvision datasets\n",
    "\n",
    " Torchvision provides functions to download and prepare popular image datasets. \n",
    " \n",
    " We're going to use the MNIST dataset, which contains images of handwritten digits. We showed in previous tutorials how we can create a MLP to classify this dataset with Keras and Tensorflow.\n",
    " \n",
    " With torchvision datasets, we usually have to pass the *ToTensor()* transform, which converts the returned images to tensors. (Note that this conversion happens when you use the dataset's *&#95;&#95;getitem&#95;&#95;* method, or in other words, when you use indexing, e.g. mnist[i]. Accessing the images directly, say by mnist.train_images, will not apply the transform and so will not return tensors.)\n",
    "\n",
    "\n",
    "*NOTE*: You should not face the error shown in tutorial if you update PyTorch (use latest version). If you wish to use the same version you have, refer to the fix [here](https://github.com/pytorch/vision/issues/3500) or [here](https://stackoverflow.com/questions/66467005/torchvision-mnist-httperror-http-error-403-forbidden): "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to mnist\\MNIST\\raw\\train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e85cac2e53494bf7945601ba150bd901",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "HTTPError",
     "evalue": "HTTP Error 403: Forbidden",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-62bc51639643>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mdownload\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mtrain\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# load the training set\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[0mtransform\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mToTensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m )\n\u001b[0;32m     10\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'number of training samples: {len(mnist)}'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Programs\\Anaconda3\\envs\\ece457b_venv\\lib\\site-packages\\torchvision\\datasets\\mnist.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, root, train, transform, target_transform, download)\u001b[0m\n\u001b[0;32m     68\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mdownload\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 70\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     71\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_exists\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Programs\\Anaconda3\\envs\\ece457b_venv\\lib\\site-packages\\torchvision\\datasets\\mnist.py\u001b[0m in \u001b[0;36mdownload\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    135\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmd5\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresources\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    136\u001b[0m             \u001b[0mfilename\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrpartition\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'/'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 137\u001b[1;33m             \u001b[0mdownload_and_extract_archive\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdownload_root\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraw_folder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmd5\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmd5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    138\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    139\u001b[0m         \u001b[1;31m# process and save as torch files\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Programs\\Anaconda3\\envs\\ece457b_venv\\lib\\site-packages\\torchvision\\datasets\\utils.py\u001b[0m in \u001b[0;36mdownload_and_extract_archive\u001b[1;34m(url, download_root, extract_root, filename, md5, remove_finished)\u001b[0m\n\u001b[0;32m    262\u001b[0m         \u001b[0mfilename\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbasename\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    263\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 264\u001b[1;33m     \u001b[0mdownload_url\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdownload_root\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmd5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    265\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    266\u001b[0m     \u001b[0marchive\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdownload_root\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Programs\\Anaconda3\\envs\\ece457b_venv\\lib\\site-packages\\torchvision\\datasets\\utils.py\u001b[0m in \u001b[0;36mdownload_url\u001b[1;34m(url, root, filename, md5)\u001b[0m\n\u001b[0;32m     95\u001b[0m                 )\n\u001b[0;32m     96\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 97\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     98\u001b[0m         \u001b[1;31m# check integrity of downloaded file\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     99\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mcheck_integrity\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmd5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Programs\\Anaconda3\\envs\\ece457b_venv\\lib\\site-packages\\torchvision\\datasets\\utils.py\u001b[0m in \u001b[0;36mdownload_url\u001b[1;34m(url, root, filename, md5)\u001b[0m\n\u001b[0;32m     83\u001b[0m             urllib.request.urlretrieve(\n\u001b[0;32m     84\u001b[0m                 \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfpath\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 85\u001b[1;33m                 \u001b[0mreporthook\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mgen_bar_updater\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     86\u001b[0m             )\n\u001b[0;32m     87\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0murllib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merror\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mURLError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mIOError\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Programs\\Anaconda3\\envs\\ece457b_venv\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36murlretrieve\u001b[1;34m(url, filename, reporthook, data)\u001b[0m\n\u001b[0;32m    245\u001b[0m     \u001b[0murl_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpath\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msplittype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    246\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 247\u001b[1;33m     \u001b[1;32mwith\u001b[0m \u001b[0mcontextlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclosing\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murlopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mfp\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    248\u001b[0m         \u001b[0mheaders\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    249\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Programs\\Anaconda3\\envs\\ece457b_venv\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36murlopen\u001b[1;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[0;32m    220\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    221\u001b[0m         \u001b[0mopener\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_opener\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 222\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mopener\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    223\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0minstall_opener\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopener\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Programs\\Anaconda3\\envs\\ece457b_venv\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36mopen\u001b[1;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[0;32m    529\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mprocessor\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprocess_response\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    530\u001b[0m             \u001b[0mmeth\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprocessor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 531\u001b[1;33m             \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmeth\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    532\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    533\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Programs\\Anaconda3\\envs\\ece457b_venv\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36mhttp_response\u001b[1;34m(self, request, response)\u001b[0m\n\u001b[0;32m    639\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m200\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[0mcode\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m300\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    640\u001b[0m             response = self.parent.error(\n\u001b[1;32m--> 641\u001b[1;33m                 'http', request, response, code, msg, hdrs)\n\u001b[0m\u001b[0;32m    642\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    643\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Programs\\Anaconda3\\envs\\ece457b_venv\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36merror\u001b[1;34m(self, proto, *args)\u001b[0m\n\u001b[0;32m    567\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mhttp_err\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    568\u001b[0m             \u001b[0margs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'default'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'http_error_default'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0morig_args\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 569\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_chain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    570\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    571\u001b[0m \u001b[1;31m# XXX probably also want an abstract factory that knows when it makes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Programs\\Anaconda3\\envs\\ece457b_venv\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36m_call_chain\u001b[1;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[0;32m    501\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhandler\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mhandlers\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    502\u001b[0m             \u001b[0mfunc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandler\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 503\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    504\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    505\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Programs\\Anaconda3\\envs\\ece457b_venv\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36mhttp_error_default\u001b[1;34m(self, req, fp, code, msg, hdrs)\u001b[0m\n\u001b[0;32m    647\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mHTTPDefaultErrorHandler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBaseHandler\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    648\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mhttp_error_default\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhdrs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 649\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mHTTPError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfull_url\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhdrs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    650\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    651\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mHTTPRedirectHandler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBaseHandler\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mHTTPError\u001b[0m: HTTP Error 403: Forbidden"
     ]
    }
   ],
   "source": [
    "from torchvision.datasets import MNIST\n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "mnist = MNIST(\n",
    "    root='mnist',  # choose a folder to save data in\n",
    "    download=True,\n",
    "    train=True,  # load the training set\n",
    "    transform=ToTensor()\n",
    ")\n",
    "print(f'number of training samples: {len(mnist)}')\n",
    "img, label = mnist[0]\n",
    "print(img.shape)\n",
    "print(label)\n",
    "plt.imshow(img.reshape(28, 28))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " To download the test dataset, pass 'train=False' instead. There are 10000 test samples.\n",
    "\n",
    "## Optimization (i.e. training the model)\n",
    "\n",
    " To train a neural net, we need 2 more things, in addition to the model and data. We need an optimizer and a loss function. PyTorch has the most commonly used loss functions implemented. For multiclass classification, we normally use the cross_entropy loss.\n",
    "\n",
    " A training iteration would go something like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x, t = next(iter(loader))  # get batch\n",
    "# y = net(x)  # forward pass\n",
    "# loss = cross_entropy(y, t)\n",
    "# compute gradients of loss wrt parameters\n",
    "# for each parameter p, update as:\n",
    "#       p <-- p - (lr * p_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Fortunately, we don't need to compute the gradients or do the updates manually. We can use one of PyTorch's optimizers to keep track of gradients and update parameters. Moreover, gradients can be computed by using the .backward() method of a tensor, which automatically backpropogates the loss. The training step now becomes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# net = ...\n",
    "# loader = ...\n",
    "# optimizer = SGD(net.parameters(), lr=0.1, momentum=0)\n",
    "# for x, t in loader\n",
    "#   y = net(x)\n",
    "#   loss = cross_entropy(y, t)\n",
    "#   optimizer.zero_grad()\n",
    "#   loss.backward()\n",
    "#   optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're using here the most basic optimizer, a vanilla stochastic gradient descent, but there more sophisticated optimizers available. \n",
    "\n",
    "Note that we need to zero_grad() in each iteration. Otherwise, the gradients would accumulate in the parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we're training the model, we need a way to gauge how well things going. We can keep track of the training loss, but that's not enough. What we're really interested in is how the model would perform on future data samples, not in seen the training set. To this end, we often use a separate validation (or dev) set while we're tuning the model hyperparameters to keep track of performance. Moreover, it is common practice to have a third set, the test set, that is only used to report the final performance after itereating between tuning and training (the dev set at this point would be \"contaminated\").\n",
    "\n",
    "The logic of all this is that once a training sample is used to modify the model's parameters in any way, the model's performance on that sample becomes biased, usually too optimistic. In other words, it would not reflect accuractely the model's performance on future samples.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Putting it all together\n",
    "\n",
    "Now that we've seen all the building blocks, let's put it all together and train a model to classify MNIST images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 100\n",
      "training batch loss = 0.4364\n",
      "accuracy = 0.8401\n",
      "batch 200\n",
      "training batch loss = 0.3836\n",
      "accuracy = 0.8757\n",
      "batch 300\n",
      "training batch loss = 0.2739\n",
      "accuracy = 0.8983\n",
      "batch 400\n",
      "training batch loss = 0.4461\n",
      "accuracy = 0.9065\n",
      "batch 500\n",
      "training batch loss = 0.4702\n",
      "accuracy = 0.9136\n",
      "batch 600\n",
      "training batch loss = 0.3497\n",
      "accuracy = 0.9185\n",
      "batch 700\n",
      "training batch loss = 0.3287\n",
      "accuracy = 0.9176\n",
      "batch 800\n",
      "training batch loss = 0.3441\n",
      "accuracy = 0.9305\n",
      "batch 900\n",
      "training batch loss = 0.4765\n",
      "accuracy = 0.9305\n",
      "batch 1000\n",
      "training batch loss = 0.1362\n",
      "accuracy = 0.9295\n"
     ]
    }
   ],
   "source": [
    "from torchvision.datasets import MNIST\n",
    "from torchvision.transforms import ToTensor\n",
    "import torch\n",
    "from torch.optim import SGD\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn.functional import cross_entropy\n",
    "from collections import OrderedDict\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "train_set = MNIST(root='mnist', download=True, train=True, transform=ToTensor())\n",
    "test_set = MNIST(root='mnist', download=True, train=False, transform=ToTensor())\n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size=60)\n",
    "test_loader = DataLoader(test_set, batch_size=50)\n",
    "\n",
    "net = torch.nn.Sequential(OrderedDict([\n",
    "    ('h1', torch.nn.Linear(784, 1024)),\n",
    "    ('a1', torch.nn.ReLU()),\n",
    "    ('h2', torch.nn.Linear(1024, 10)),\n",
    "]))\n",
    "\n",
    "net.to(device)\n",
    "optimizer = SGD(net.parameters(), lr=0.01, momentum=0.9)\n",
    "for i, (x, t) in enumerate(train_loader):\n",
    "    x = x.view(-1, 784)  # flatten images into vectors\n",
    "    x = x.to(device)\n",
    "    t = t.to(device)\n",
    "    y = net(x)\n",
    "    loss = cross_entropy(y, t)\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if (i + 1) % 100 == 0:\n",
    "        print(f'batch {i + 1}')\n",
    "        # normally, we would track the average loss over\n",
    "        # a number of batches. A single batch loss oscillates\n",
    "        # from one batch to another, but used here just\n",
    "        # to illustrate.\n",
    "        print(f'training batch loss = {loss.item():.4f}')\n",
    "        correct = 0.\n",
    "        total = 0.\n",
    "        for x, t in test_loader:\n",
    "            x = x.view(-1, 784)\n",
    "            x = x.to(device)\n",
    "            t = t.to(device)\n",
    "            y = net(x)\n",
    "            c = y.argmax(dim=1)\n",
    "            correct += t.eq(c).sum().item()\n",
    "            total += t.shape[0]\n",
    "        print(f'accuracy = {correct / total}')\n",
    "        \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
